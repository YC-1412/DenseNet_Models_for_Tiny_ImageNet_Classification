{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymoCl9w_OCrZ"
   },
   "outputs": [],
   "source": [
    "# not run in GCP\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/MyDrive/0-ECBM_4040-DL/DL_final_project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tux6uLXhOAaF"
   },
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErIw7bNuOAaK"
   },
   "outputs": [],
   "source": [
    "# !pip install imgaug\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from utils import download_data, load_data, data_augmentation, get_labels\n",
    "from visualization import show_sample, plot_loss, show_prediction\n",
    "from models import init_model_1, init_model_2, training, save_model, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsmhZpbbRMET"
   },
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "checkpoint_filepath = './modelcheckpoints'\n",
    "model_path = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkEs9eM_OAaL"
   },
   "outputs": [],
   "source": [
    "# not run in GCP\n",
    "# data_path = '/content/drive/MyDrive/0-ECBM_4040-DL/DL_final_project/data'\n",
    "# checkpoint_filepath = '/content/drive/MyDrive/0-ECBM_4040-DL/DL_final_project/modelcheckpoints'\n",
    "# model_path = '/content/drive/MyDrive/0-ECBM_4040-DL/DL_final_project/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9E63kZj5OAaL"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7704,
     "status": "ok",
     "timestamp": 1608395736647,
     "user": {
      "displayName": "Yingyu Cao",
      "photoUrl": "https://lh4.googleusercontent.com/-1hQkdsgYrWk/AAAAAAAAAAI/AAAAAAAAAE4/6dhXqWayhPk/s64/photo.jpg",
      "userId": "04224777957403955484"
     },
     "user_tz": 300
    },
    "id": "JmQ9Y3gZOAaL",
    "outputId": "0d7e3771-f15e-42c8-edd2-fee602e7a705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading...\n",
      "Found 80000 images belonging to 200 classes.\n",
      "Found 20000 images belonging to 200 classes.\n",
      "Training data shape: (80000, 64, 64, 3)\n",
      "Validation data shape: (20000, 64, 64, 3)\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n",
      "Testing data shape: (10000, 64, 64, 3)\n",
      "End loading!\n"
     ]
    }
   ],
   "source": [
    "# if data is not downloaded, will download first\n",
    "train_generator, val_generator, test_generator = load_data(data_path, img_width=64, img_height=64, \n",
    "                                           batch_size=128, augmentation=None, seed=None, load_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k9jo_65OAaM"
   },
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11627,
     "status": "ok",
     "timestamp": 1608395741617,
     "user": {
      "displayName": "Yingyu Cao",
      "photoUrl": "https://lh4.googleusercontent.com/-1hQkdsgYrWk/AAAAAAAAAAI/AAAAAAAAAE4/6dhXqWayhPk/s64/photo.jpg",
      "userId": "04224777957403955484"
     },
     "user_tz": 300
    },
    "id": "LwJBXiREOAaM",
    "outputId": "767cfee3-6802-460a-fa2f-212d7626fc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading...\n",
      "Found 80000 images belonging to 200 classes.\n",
      "Found 20000 images belonging to 200 classes.\n",
      "Training data shape: (80000, 64, 64, 3)\n",
      "Validation data shape: (20000, 64, 64, 3)\n",
      "End loading!\n"
     ]
    }
   ],
   "source": [
    "# parameters for data_augmentation function\n",
    "# use ?data_aug_args to see details for those paramters\n",
    "data_aug_args = dict(CoarseDropout_range=(0.0, 0.05),\n",
    "                     CoarseDropout_size_percent=(0.02, 0.25),\n",
    "                     Affine_translate_percent=(-0.2, 0.2),\n",
    "                     Affine_scale=(0.5, 1.5),\n",
    "                     Affine_shear=(-20, 20),\n",
    "                     Affine_rotate=(-45, 45),\n",
    "                     Flip_percent=0.5,\n",
    "                     GaussianBlur_sigma=(0.0, 3.0),\n",
    "                     CropAndPad_percent=(-0.25, 0.25),\n",
    "                     Multiply=(0.5, 1.5),\n",
    "                     LinearContrast=(0.4, 1.6),\n",
    "                     AdditiveGaussianNoise_scale=0.2*255)\n",
    "# get augmnetation function\n",
    "# complicated=True: augmentation for network 2, false: augmentation for network 1\n",
    "aug = data_augmentation(complicated=False, **data_aug_args)\n",
    "\n",
    "# get augmented data generator\n",
    "train_generator_aug, val_generator_aug = load_data(data_path, img_width=64, img_height=64, \n",
    "                                                   batch_size=128, augmentation=aug, \n",
    "                                                   seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJa_Xrr9OAaN"
   },
   "source": [
    "## Model 1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4059,
     "status": "ok",
     "timestamp": 1608395742822,
     "user": {
      "displayName": "Yingyu Cao",
      "photoUrl": "https://lh4.googleusercontent.com/-1hQkdsgYrWk/AAAAAAAAAAI/AAAAAAAAAE4/6dhXqWayhPk/s64/photo.jpg",
      "userId": "04224777957403955484"
     },
     "user_tz": 300
    },
    "id": "zn7p8on3OAaO",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f7da6d6d-2d10-4320-cd9a-50ab947732e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 3 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None, 3 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 6 18432       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 6 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 1 73728       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 1 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 2 294912      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 2 1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 2 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 5 1179648     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 5 2048        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 5 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, None, None, 5 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 294912      max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 6 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 73728       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 1 512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 1 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 2 294912      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 2 1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 2 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 5 1179648     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 5 2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 5 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 1 4718592     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 1 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SpaceToDepth (Tenso [(None, None, None,  0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 3 0           tf_op_layer_SpaceToDepth[0][0]   \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 3 884736      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 3 128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 3 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 1 36864       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 2 294912      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 5 1179648     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 5 2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 5 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 1 4718592     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 1 4096        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 1 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SpaceToDepth_1 (Ten [(None, None, None,  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 1 0           tf_op_layer_SpaceToDepth_1[0][0] \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 2 2662400     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 2 800         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 200)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 200)          0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 17,927,040\n",
      "Trainable params: 17,916,784\n",
      "Non-trainable params: 10,256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# init model 1 with the same architecture in the paper\n",
    "model1 = init_model_1((None,None,3))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "iPu4s0VpOAaO",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "# optimizer: Adam\n",
    "opt = Adam()\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aOKduQ6PS8m"
   },
   "source": [
    "### Train model 1 with 32x32 data and 8 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1480476,
     "status": "ok",
     "timestamp": 1608397239078,
     "user": {
      "displayName": "Yingyu Cao",
      "photoUrl": "https://lh4.googleusercontent.com/-1hQkdsgYrWk/AAAAAAAAAAI/AAAAAAAAAE4/6dhXqWayhPk/s64/photo.jpg",
      "userId": "04224777957403955484"
     },
     "user_tz": 300
    },
    "id": "BMicHBI_S3uE",
    "outputId": "84bfa8e9-d71b-4c97-9ba7-b9b202a64e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading...\n",
      "Found 80000 images belonging to 200 classes.\n",
      "Found 20000 images belonging to 200 classes.\n",
      "Training data shape: (80000, 32, 32, 3)\n",
      "Validation data shape: (20000, 32, 32, 3)\n",
      "End loading!\n",
      "Epoch 1/8\n",
      "200/200 [==============================] - 173s 864ms/step - loss: 4.7436 - accuracy: 0.0637 - val_loss: 5.6997 - val_accuracy: 0.0097 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "200/200 [==============================] - 171s 855ms/step - loss: 4.3448 - accuracy: 0.1113 - val_loss: 5.2052 - val_accuracy: 0.0286 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "200/200 [==============================] - 171s 855ms/step - loss: 4.1007 - accuracy: 0.1464 - val_loss: 4.4308 - val_accuracy: 0.0898 - lr: 0.0010\n",
      "Epoch 4/8\n",
      "200/200 [==============================] - 171s 856ms/step - loss: 3.9054 - accuracy: 0.1732 - val_loss: 4.1942 - val_accuracy: 0.1256 - lr: 0.0010\n",
      "Epoch 5/8\n",
      "200/200 [==============================] - 171s 855ms/step - loss: 3.7320 - accuracy: 0.2036 - val_loss: 3.9762 - val_accuracy: 0.1548 - lr: 0.0010\n",
      "Epoch 6/8\n",
      "200/200 [==============================] - 171s 853ms/step - loss: 3.5810 - accuracy: 0.2261 - val_loss: 4.1371 - val_accuracy: 0.1370 - lr: 0.0010\n",
      "Epoch 7/8\n",
      "200/200 [==============================] - 171s 853ms/step - loss: 3.4509 - accuracy: 0.2482 - val_loss: 4.0484 - val_accuracy: 0.1461 - lr: 0.0010\n",
      "Epoch 8/8\n",
      "200/200 [==============================] - 171s 856ms/step - loss: 3.3319 - accuracy: 0.2669 - val_loss: 3.7913 - val_accuracy: 0.1834 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# get data generator\n",
    "train_generator_32, val_generator_32 = load_data(data_path, img_width=32, img_height=32, \n",
    "                                           batch_size=128, augmentation=None, seed=None)\n",
    "# train model\n",
    "callback = ReduceLROnPlateau(patience=5, min_lr=6e-7)\n",
    "model1_1, history1_1 = training(model1, 'model1_1', train_generator_32, val_generator_32, \n",
    "                           callback, checkpoint_filepath, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1407,
     "status": "ok",
     "timestamp": 1608397402374,
     "user": {
      "displayName": "Yingyu Cao",
      "photoUrl": "https://lh4.googleusercontent.com/-1hQkdsgYrWk/AAAAAAAAAAI/AAAAAAAAAE4/6dhXqWayhPk/s64/photo.jpg",
      "userId": "04224777957403955484"
     },
     "user_tz": 300
    },
    "id": "lPcKgOW1lBvP",
    "outputId": "1f2115b5-fa6d-4267-e6a3-2ecbdca6b13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1_1_12-19_21-03.h5 saved at ./model!\n"
     ]
    }
   ],
   "source": [
    "# save model periodically\n",
    "save_model(model1_1, 'model1_1', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgFIYIf7Pv1H"
   },
   "source": [
    "### Train model 1 with 64x64 data and 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWWYpZiBPQ1X",
    "outputId": "06cbe299-b7a5-4526-a3ec-c07b714ad615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading...\n",
      "Found 80000 images belonging to 200 classes.\n",
      "Found 20000 images belonging to 200 classes.\n",
      "Training data shape: (80000, 64, 64, 3)\n",
      "Validation data shape: (20000, 64, 64, 3)\n",
      "End loading!\n",
      "Epoch 1/15\n",
      "200/200 [==============================] - 657s 3s/step - loss: 3.4248 - accuracy: 0.2752 - val_loss: 3.8398 - val_accuracy: 0.1708 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 3.2477 - accuracy: 0.2971 - val_loss: 3.4940 - val_accuracy: 0.2228 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 3.1201 - accuracy: 0.3204 - val_loss: 3.5342 - val_accuracy: 0.2211 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 3.0076 - accuracy: 0.3362 - val_loss: 3.4691 - val_accuracy: 0.2409 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.9203 - accuracy: 0.3473 - val_loss: 3.4291 - val_accuracy: 0.2390 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.8368 - accuracy: 0.3595 - val_loss: 3.5410 - val_accuracy: 0.2229 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.7332 - accuracy: 0.3810 - val_loss: 3.0715 - val_accuracy: 0.3062 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.6308 - accuracy: 0.3993 - val_loss: 3.1793 - val_accuracy: 0.2830 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.5248 - accuracy: 0.4248 - val_loss: 3.1515 - val_accuracy: 0.2891 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.4728 - accuracy: 0.4301 - val_loss: 3.0599 - val_accuracy: 0.3006 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.3980 - accuracy: 0.4468 - val_loss: 3.0493 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.3094 - accuracy: 0.4645 - val_loss: 2.8237 - val_accuracy: 0.3559 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "200/200 [==============================] - 654s 3s/step - loss: 2.2559 - accuracy: 0.4743 - val_loss: 2.8002 - val_accuracy: 0.3556 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.1622 - accuracy: 0.4962 - val_loss: 2.8134 - val_accuracy: 0.3542 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.1077 - accuracy: 0.5064 - val_loss: 2.7081 - val_accuracy: 0.3692 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# get data generator\n",
    "train_generator_64, val_generator_64 = load_data(data_path, img_width=64, img_height=64, \n",
    "                                           batch_size=128, augmentation=None, seed=None)\n",
    "# train model\n",
    "model1_2, history1_2 = training(model1_1, 'model1_2', train_generator_64, val_generator_64, \n",
    "                           callback, checkpoint_filepath, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYO4IYsrlVkf",
    "outputId": "4e2b815a-b1ec-4026-cca8-1b223ba6450c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1_2_12-19_23-47.h5 saved at ./model!\n"
     ]
    }
   ],
   "source": [
    "# save model periodically\n",
    "save_model(model1_2, 'model1_2', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNNJGlI8RMEX"
   },
   "source": [
    "### Train model 1 with 16x16 data and 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxLOyLFXRMEX",
    "outputId": "2c8ba9fc-57f1-47e9-f3ad-a30291108659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading...\n",
      "Found 80000 images belonging to 200 classes.\n",
      "Found 20000 images belonging to 200 classes.\n",
      "Training data shape: (80000, 16, 16, 3)\n",
      "Validation data shape: (20000, 16, 16, 3)\n",
      "End loading!\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 3.6970 - accuracy: 0.1988 - val_loss: 3.6112 - val_accuracy: 0.2152 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 3.1337 - accuracy: 0.2840 - val_loss: 3.5588 - val_accuracy: 0.2263 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 2.9498 - accuracy: 0.3224 - val_loss: 3.4739 - val_accuracy: 0.2382 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 2.7399 - accuracy: 0.3602 - val_loss: 3.4253 - val_accuracy: 0.2551 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 2.5912 - accuracy: 0.3966 - val_loss: 3.3134 - val_accuracy: 0.2623 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# get data generator\n",
    "train_generator_16, val_generator_16 = load_data(data_path, img_width=16, img_height=16, \n",
    "                                           batch_size=128, augmentation=None, seed=None)\n",
    "# train model\n",
    "model1_3, history1_3 = training(model1_2, 'model1_3', train_generator_16, val_generator_16, \n",
    "                           callback, checkpoint_filepath, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87F9zQUsRMEX",
    "outputId": "78eee456-d591-44ef-9e06-132aa46f0da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1_3_12-19_23-57.h5 saved at ./model!\n"
     ]
    }
   ],
   "source": [
    "# save model periodically\n",
    "save_model(model1_3, 'model1_3', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjusRDyIRMEX"
   },
   "source": [
    "### Train model 1 with 64x64 data and 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EC_7fhjRMEY",
    "outputId": "14e20cf1-7675-4668-af80-034d0296a906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading...\n",
      "Found 80000 images belonging to 200 classes.\n",
      "Found 20000 images belonging to 200 classes.\n",
      "Training data shape: (80000, 64, 64, 3)\n",
      "Validation data shape: (20000, 64, 64, 3)\n",
      "End loading!\n",
      "Epoch 1/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.4367 - accuracy: 0.4443 - val_loss: 2.7572 - val_accuracy: 0.3751 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.0930 - accuracy: 0.5083 - val_loss: 2.7404 - val_accuracy: 0.3756 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9781 - accuracy: 0.5350 - val_loss: 2.6057 - val_accuracy: 0.3925 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 1.8943 - accuracy: 0.5509 - val_loss: 2.4974 - val_accuracy: 0.4119 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.8356 - accuracy: 0.5660 - val_loss: 2.4524 - val_accuracy: 0.4211 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 1.7760 - accuracy: 0.5759 - val_loss: 2.4042 - val_accuracy: 0.4287 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "200/200 [==============================] - 651s 3s/step - loss: 1.7047 - accuracy: 0.5957 - val_loss: 2.5369 - val_accuracy: 0.4085 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.6281 - accuracy: 0.6134 - val_loss: 2.4667 - val_accuracy: 0.4221 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.5934 - accuracy: 0.6201 - val_loss: 2.3771 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "200/200 [==============================] - 653s 3s/step - loss: 1.5112 - accuracy: 0.6408 - val_loss: 2.7352 - val_accuracy: 0.3774 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.4771 - accuracy: 0.6471 - val_loss: 2.5557 - val_accuracy: 0.4100 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.4001 - accuracy: 0.6668 - val_loss: 2.5749 - val_accuracy: 0.4101 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.3520 - accuracy: 0.6800 - val_loss: 2.4821 - val_accuracy: 0.4248 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.2862 - accuracy: 0.6966 - val_loss: 2.2778 - val_accuracy: 0.4654 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "200/200 [==============================] - 651s 3s/step - loss: 1.2312 - accuracy: 0.7076 - val_loss: 2.3517 - val_accuracy: 0.4497 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# get data generator\n",
    "train_generator_64, val_generator_64 = load_data(data_path, img_width=64, img_height=64, \n",
    "                                           batch_size=128, augmentation=None, seed=None)\n",
    "# train model\n",
    "model1_4, history1_4 = training(model1_3, 'model1_4', train_generator_64, val_generator_64, \n",
    "                           callback, checkpoint_filepath, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCuSSi2dRMEY",
    "outputId": "1eae3171-ef6d-45ed-e22a-86392715f11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1_4_12-20_02-41.h5 saved at ./model!\n"
     ]
    }
   ],
   "source": [
    "# save model periodically\n",
    "save_model(model1_4, 'model1_4', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F37Io0n-P1SU"
   },
   "source": [
    "### Train model 1 with 64x64 augmented data and 75 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZsBcW83RMEY"
   },
   "outputs": [],
   "source": [
    "callback = ReduceLROnPlateau(patience=5, min_lr=6e-7)\n",
    "model1_4 = tf.keras.models.load_model(model_path+'/model1_4_12-20_02-41.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4g0SqbQkzgR",
    "outputId": "93686959-b9ad-4c46-c830-460be1e40e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading...\n",
      "Found 80000 images belonging to 200 classes.\n",
      "Found 20000 images belonging to 200 classes.\n",
      "Training data shape: (80000, 64, 64, 3)\n",
      "Validation data shape: (20000, 64, 64, 3)\n",
      "End loading!\n",
      "Epoch 1/75\n",
      "200/200 [==============================] - 658s 3s/step - loss: 3.2838 - accuracy: 0.2901 - val_loss: 3.9038 - val_accuracy: 0.2050 - lr: 0.0010\n",
      "Epoch 2/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 3.0117 - accuracy: 0.3256 - val_loss: 4.1169 - val_accuracy: 0.1884 - lr: 0.0010\n",
      "Epoch 3/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.9457 - accuracy: 0.3389 - val_loss: 3.7188 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 4/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.8884 - accuracy: 0.3482 - val_loss: 3.4911 - val_accuracy: 0.2490 - lr: 0.0010\n",
      "Epoch 5/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.8286 - accuracy: 0.3630 - val_loss: 3.7666 - val_accuracy: 0.2224 - lr: 0.0010\n",
      "Epoch 6/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.7923 - accuracy: 0.3657 - val_loss: 3.5015 - val_accuracy: 0.2540 - lr: 0.0010\n",
      "Epoch 7/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.7560 - accuracy: 0.3791 - val_loss: 3.8210 - val_accuracy: 0.2180 - lr: 0.0010\n",
      "Epoch 8/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.7378 - accuracy: 0.3779 - val_loss: 3.5436 - val_accuracy: 0.2564 - lr: 0.0010\n",
      "Epoch 9/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.7071 - accuracy: 0.3841 - val_loss: 3.3471 - val_accuracy: 0.2749 - lr: 0.0010\n",
      "Epoch 10/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.6720 - accuracy: 0.3930 - val_loss: 3.4009 - val_accuracy: 0.2672 - lr: 0.0010\n",
      "Epoch 11/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.6587 - accuracy: 0.3934 - val_loss: 3.2038 - val_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 12/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.6535 - accuracy: 0.3957 - val_loss: 3.3371 - val_accuracy: 0.2788 - lr: 0.0010\n",
      "Epoch 13/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.6065 - accuracy: 0.3998 - val_loss: 3.3384 - val_accuracy: 0.2761 - lr: 0.0010\n",
      "Epoch 14/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.5781 - accuracy: 0.4096 - val_loss: 3.1564 - val_accuracy: 0.3036 - lr: 0.0010\n",
      "Epoch 15/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.5635 - accuracy: 0.4080 - val_loss: 3.1905 - val_accuracy: 0.2988 - lr: 0.0010\n",
      "Epoch 16/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.5704 - accuracy: 0.4101 - val_loss: 3.1217 - val_accuracy: 0.3120 - lr: 0.0010\n",
      "Epoch 17/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.5246 - accuracy: 0.4175 - val_loss: 3.1117 - val_accuracy: 0.3171 - lr: 0.0010\n",
      "Epoch 18/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.5132 - accuracy: 0.4196 - val_loss: 3.1590 - val_accuracy: 0.3071 - lr: 0.0010\n",
      "Epoch 19/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.4656 - accuracy: 0.4323 - val_loss: 3.1488 - val_accuracy: 0.3097 - lr: 0.0010\n",
      "Epoch 20/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.4685 - accuracy: 0.4280 - val_loss: 3.1617 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 21/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.4601 - accuracy: 0.4313 - val_loss: 3.3307 - val_accuracy: 0.2852 - lr: 0.0010\n",
      "Epoch 22/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.4386 - accuracy: 0.4341 - val_loss: 3.1320 - val_accuracy: 0.3090 - lr: 0.0010\n",
      "Epoch 23/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.2807 - accuracy: 0.4692 - val_loss: 2.7010 - val_accuracy: 0.3890 - lr: 1.0000e-04\n",
      "Epoch 24/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.2262 - accuracy: 0.4818 - val_loss: 2.6850 - val_accuracy: 0.3918 - lr: 1.0000e-04\n",
      "Epoch 25/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.1842 - accuracy: 0.4881 - val_loss: 2.6598 - val_accuracy: 0.3954 - lr: 1.0000e-04\n",
      "Epoch 26/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.1755 - accuracy: 0.4945 - val_loss: 2.6399 - val_accuracy: 0.4009 - lr: 1.0000e-04\n",
      "Epoch 27/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.1641 - accuracy: 0.4939 - val_loss: 2.6352 - val_accuracy: 0.4009 - lr: 1.0000e-04\n",
      "Epoch 28/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.1483 - accuracy: 0.4982 - val_loss: 2.6281 - val_accuracy: 0.3998 - lr: 1.0000e-04\n",
      "Epoch 29/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.1419 - accuracy: 0.4988 - val_loss: 2.6528 - val_accuracy: 0.3992 - lr: 1.0000e-04\n",
      "Epoch 30/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.1121 - accuracy: 0.5081 - val_loss: 2.6379 - val_accuracy: 0.3992 - lr: 1.0000e-04\n",
      "Epoch 31/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.1193 - accuracy: 0.5075 - val_loss: 2.6205 - val_accuracy: 0.4022 - lr: 1.0000e-04\n",
      "Epoch 32/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.1048 - accuracy: 0.5108 - val_loss: 2.6426 - val_accuracy: 0.3957 - lr: 1.0000e-04\n",
      "Epoch 33/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.1029 - accuracy: 0.5081 - val_loss: 2.6207 - val_accuracy: 0.4060 - lr: 1.0000e-04\n",
      "Epoch 34/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0890 - accuracy: 0.5088 - val_loss: 2.6104 - val_accuracy: 0.4052 - lr: 1.0000e-04\n",
      "Epoch 35/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0819 - accuracy: 0.5150 - val_loss: 2.6192 - val_accuracy: 0.4011 - lr: 1.0000e-04\n",
      "Epoch 36/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0710 - accuracy: 0.5157 - val_loss: 2.6125 - val_accuracy: 0.4042 - lr: 1.0000e-04\n",
      "Epoch 37/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0619 - accuracy: 0.5173 - val_loss: 2.6276 - val_accuracy: 0.4009 - lr: 1.0000e-04\n",
      "Epoch 38/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0541 - accuracy: 0.5200 - val_loss: 2.6226 - val_accuracy: 0.4049 - lr: 1.0000e-04\n",
      "Epoch 39/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0611 - accuracy: 0.5230 - val_loss: 2.6072 - val_accuracy: 0.4056 - lr: 1.0000e-04\n",
      "Epoch 40/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.0456 - accuracy: 0.5209 - val_loss: 2.6141 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 41/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0607 - accuracy: 0.5164 - val_loss: 2.6143 - val_accuracy: 0.4033 - lr: 1.0000e-04\n",
      "Epoch 42/75\n",
      "200/200 [==============================] - 651s 3s/step - loss: 2.0285 - accuracy: 0.5245 - val_loss: 2.6009 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 43/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0288 - accuracy: 0.5254 - val_loss: 2.6077 - val_accuracy: 0.4060 - lr: 1.0000e-04\n",
      "Epoch 44/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0393 - accuracy: 0.5233 - val_loss: 2.5836 - val_accuracy: 0.4077 - lr: 1.0000e-04\n",
      "Epoch 45/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0346 - accuracy: 0.5236 - val_loss: 2.5900 - val_accuracy: 0.4099 - lr: 1.0000e-04\n",
      "Epoch 46/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0278 - accuracy: 0.5229 - val_loss: 2.5801 - val_accuracy: 0.4134 - lr: 1.0000e-04\n",
      "Epoch 47/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 2.0043 - accuracy: 0.5345 - val_loss: 2.5791 - val_accuracy: 0.4139 - lr: 1.0000e-04\n",
      "Epoch 48/75\n",
      "200/200 [==============================] - 651s 3s/step - loss: 1.9983 - accuracy: 0.5328 - val_loss: 2.5865 - val_accuracy: 0.4117 - lr: 1.0000e-04\n",
      "Epoch 49/75\n",
      "200/200 [==============================] - 651s 3s/step - loss: 1.9935 - accuracy: 0.5344 - val_loss: 2.5791 - val_accuracy: 0.4123 - lr: 1.0000e-04\n",
      "Epoch 50/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 2.0038 - accuracy: 0.5313 - val_loss: 2.5950 - val_accuracy: 0.4040 - lr: 1.0000e-04\n",
      "Epoch 51/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9995 - accuracy: 0.5305 - val_loss: 2.5852 - val_accuracy: 0.4096 - lr: 1.0000e-04\n",
      "Epoch 52/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9840 - accuracy: 0.5359 - val_loss: 2.6221 - val_accuracy: 0.4043 - lr: 1.0000e-04\n",
      "Epoch 53/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9886 - accuracy: 0.5318 - val_loss: 2.5728 - val_accuracy: 0.4126 - lr: 1.0000e-05\n",
      "Epoch 54/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 1.9800 - accuracy: 0.5388 - val_loss: 2.5680 - val_accuracy: 0.4159 - lr: 1.0000e-05\n",
      "Epoch 55/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9630 - accuracy: 0.5396 - val_loss: 2.5786 - val_accuracy: 0.4129 - lr: 1.0000e-05\n",
      "Epoch 56/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9843 - accuracy: 0.5354 - val_loss: 2.5553 - val_accuracy: 0.4141 - lr: 1.0000e-05\n",
      "Epoch 57/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9770 - accuracy: 0.5377 - val_loss: 2.5657 - val_accuracy: 0.4126 - lr: 1.0000e-05\n",
      "Epoch 58/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9597 - accuracy: 0.5426 - val_loss: 2.5481 - val_accuracy: 0.4161 - lr: 1.0000e-05\n",
      "Epoch 59/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 1.9611 - accuracy: 0.5434 - val_loss: 2.5562 - val_accuracy: 0.4177 - lr: 1.0000e-05\n",
      "Epoch 60/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9519 - accuracy: 0.5455 - val_loss: 2.5450 - val_accuracy: 0.4160 - lr: 1.0000e-05\n",
      "Epoch 61/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9726 - accuracy: 0.5374 - val_loss: 2.5470 - val_accuracy: 0.4166 - lr: 1.0000e-05\n",
      "Epoch 62/75\n",
      "200/200 [==============================] - 653s 3s/step - loss: 1.9623 - accuracy: 0.5400 - val_loss: 2.5428 - val_accuracy: 0.4187 - lr: 1.0000e-05\n",
      "Epoch 63/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9684 - accuracy: 0.5416 - val_loss: 2.5603 - val_accuracy: 0.4132 - lr: 1.0000e-05\n",
      "Epoch 64/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9478 - accuracy: 0.5445 - val_loss: 2.5595 - val_accuracy: 0.4141 - lr: 1.0000e-05\n",
      "Epoch 65/75\n",
      "200/200 [==============================] - 652s 3s/step - loss: 1.9609 - accuracy: 0.5423 - val_loss: 2.5563 - val_accuracy: 0.4136 - lr: 1.0000e-05\n",
      "Epoch 66/75\n",
      " 73/200 [=========>....................] - ETA: 5:32 - loss: 1.9809 - accuracy: 0.5352"
     ]
    }
   ],
   "source": [
    "# get augmnetation function\n",
    "# complicated=True: augmentation for network 2, false: augmentation for network 1\n",
    "aug = data_augmentation(complicated=False, **data_aug_args)\n",
    "# get data generator\n",
    "train_generator_aug, val_generator_aug = load_data(data_path, img_width=64, img_height=64, \n",
    "                                           batch_size=128, augmentation=aug, seed=None)\n",
    "# train model\n",
    "model1_5, history1_5 = training(model1_4, 'model1_5', train_generator_aug, val_generator_aug, \n",
    "                           callback, checkpoint_filepath, epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80dPM8BIlWZl"
   },
   "outputs": [],
   "source": [
    "# save model periodically\n",
    "save_model(model1_5, 'model1_5', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJXBmJWASAtT"
   },
   "source": [
    "Due to the limitation of computing resource, we could not run all 75 epochs in 12 hours and the training ended in the 66th epoch."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main_model1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
