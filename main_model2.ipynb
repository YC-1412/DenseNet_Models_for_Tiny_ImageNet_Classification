{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "main_model2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-tbPKFaXoBx",
        "outputId": "e38a7bf1-1417-4697-c982-05f864a909d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSe0GMAbXzQf"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/4040')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tux6uLXhOAaF"
      },
      "source": [
        "## 1. Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC6-BIm19TQh"
      },
      "source": [
        "\r\n",
        "%load_ext autoreload\r\n",
        "%autoreload 2\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErIw7bNuOAaK"
      },
      "source": [
        "# !pip install imgaug\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop, SGD\n",
        "from utils import load_data, data_augmentation, show_sample, get_labels\n",
        "from models import init_model_1, init_model_2, training, save_model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DKcKK0Q-FN_"
      },
      "source": [
        "from models import init_model_1, init_model_2,resblock, training, save_model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qon-gtGGcm8c"
      },
      "source": [
        "# 2. Load Data Set & Data Path\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy0E_bu7my0o",
        "outputId": "b7260f13-b5d9-4252-e021-35dc4f484133"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\r\n",
        "!unzip -qq 'tiny-imagenet-200.zip'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-21 01:48:44--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  11.6MB/s    in 13s     \n",
            "\n",
            "2020-12-21 01:48:57 (18.1 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmQ9Y3gZOAaL",
        "outputId": "9140f550-e250-4467-8ce8-6c9a7b7f5fc1"
      },
      "source": [
        "train_generator, val_generator, test_generator = load_data(data_path, img_width=64, img_height=64, \n",
        "                                           batch_size=128, augmentation=None, seed=101, load_test=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start downloading data...\n",
            "Download complete.\n",
            "Begin extracting...\n",
            "Unzip complete.\n",
            "Found 80000 images belonging to 200 classes.\n",
            "Found 20000 images belonging to 200 classes.\n",
            "Training data shape: (80000, 64, 64, 3)\n",
            "Validation data shape: (20000, 64, 64, 3)\n",
            "Found 10000 validated image filenames belonging to 200 classes.\n",
            "Testing data shape: (10000, 64, 64, 3)\n",
            "End loading!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkEs9eM_OAaL"
      },
      "source": [
        "data_path = '/content/tiny-imagenet-200'\r\n",
        "checkpoint_filepath = '/content/drive/MyDrive/Colab Notebooks/4040/checkpoints'\r\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/4040/savedmodel'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k9jo_65OAaM"
      },
      "source": [
        "# 3. Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwJBXiREOAaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc79bb1-0654-46a6-aa20-827d337a3786"
      },
      "source": [
        "# parameters for data_augmentation function\n",
        "# use ?data_aug_args to see details for those paramters\n",
        "data_aug_args = dict(CoarseDropout_range=(0.0, 0.05),\n",
        "                     CoarseDropout_size_percent=(0.02, 0.25),\n",
        "                     Affine_translate_percent=(-0.2, 0.2),\n",
        "                     Affine_scale=(0.5, 1.5),\n",
        "                     Affine_shear=(-20, 20),\n",
        "                     Affine_rotate=(-45, 45),\n",
        "                     Flip_percent=0.5,\n",
        "                     GaussianBlur_sigma=(0.0, 3.0),\n",
        "                     CropAndPad_percent=(-0.25, 0.25),\n",
        "                     Multiply=(0.5, 1.5),\n",
        "                     LinearContrast=(0.4, 1.6),\n",
        "                     AdditiveGaussianNoise_scale=0.2*255)\n",
        "# get augmnetation function\n",
        "# complicated=True: augmentation for network 2, false: augmentation for network 1\n",
        "aug = data_augmentation(complicated=False, **data_aug_args)\n",
        "\n",
        "# get augmented data generator\n",
        "train_generator_aug, val_generator_aug = load_data(data_path, img_width=64, img_height=64, \n",
        "                                                   batch_size=128, augmentation=aug, \n",
        "                                                   seed=101)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin loading...\n",
            "Found 80000 images belonging to 200 classes.\n",
            "Found 20000 images belonging to 200 classes.\n",
            "Training data shape: (80000, 64, 64, 3)\n",
            "Validation data shape: (20000, 64, 64, 3)\n",
            "End loading!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qV88mgwOAaO"
      },
      "source": [
        "## 4. Model 2 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPJvkZIgCcnG"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation, GlobalAveragePooling2D\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SeparableConv2D\r\n",
        "from keras.optimizers import Adam, RMSprop, SGD\r\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\r\n",
        "from keras.layers.merge import concatenate\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0p1hfuqOAaO"
      },
      "source": [
        "model2 = init_model_2((64,64,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOSC6HUzDIKo",
        "outputId": "7a9855d2-2c95-46ea-d81b-20bfc8b330d9"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 32)   896         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 128)  36992       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 128)  147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 128)  147584      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 160)  0           activation_5[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 160)  640         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 64, 160)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 160)  0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 256)  368896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 256)  590080      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 256)  1024        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 256)  590080      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 256)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 416)  0           max_pooling2d[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 416)  1664        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 416)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 416)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 512)  1917440     max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 512)  2048        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 512)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 512)  2359808     activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 512)  2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 512)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 512)  2359808     activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 512)  2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 512)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 512)  2359808     activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 512)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 928)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 928)  3712        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 928)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 928)    0           activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 928)    0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 200)    185800      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 11,822,920\n",
            "Trainable params: 11,812,680\n",
            "Non-trainable params: 10,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5drzC51otWA"
      },
      "source": [
        "The orginal paper used Cyclic Learning Rate, we apply the same CyclicLR function using the same code from https://github.com/ZohebAbai/Tiny-ImageNet-Challenge/blob/master/TinyImageNet_Network_2.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POoAxoYPoxlK",
        "outputId": "974bbb79-8137-431b-f947-e1fd22f21789"
      },
      "source": [
        "!pip install git+https://github.com/keras-team/keras-contrib.git\r\n",
        "from keras_contrib.callbacks import CyclicLR"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-4j85hltb\n",
            "  Running command git clone -q https://github.com/keras-team/keras-contrib.git /tmp/pip-req-build-4j85hltb\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=d543814d6952b9596278ae40ad848fa1fbd4ab2938cfa7a1adac1f2ac09012b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tui8j_3v/wheels/eb/42/ea/ef324c6958836b1a3d4c0659214b0bae1c0a9bf151254dc93f\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0hbssIgqdT4"
      },
      "source": [
        "opt1=RMSprop(lr= 1e-4, epsilon=1e-08)\r\n",
        "opt2= Adam(lr= 1e-4, epsilon=1e-08)\r\n",
        "opt3= SGD(momentum=0.9)\r\n",
        "\r\n",
        "\r\n",
        "model2.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt2,\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpOHk7FmSAG8"
      },
      "source": [
        "# After disconnecting and saving the model, run the new model from here after skipping the above part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiH-_dCnRfiv"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "new_model2 = load_model(\"/content/drive/MyDrive/Colab Notebooks/4040/checkpoints/model2_12-19_22-11.07.h5\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBXrSWceOAaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d786d2-cdff-4f17-9f4d-14af5ff9872d"
      },
      "source": [
        "# get augmnetation function\n",
        "# complicated=True: augmentation for network 2, false: augmentation for network 1\n",
        "aug = data_augmentation(complicated=True, **data_aug_args)\n",
        "clr = CyclicLR(base_lr=0.0001, max_lr=0.0006, step_size=4686., mode='triangular2')\n",
        "train_generator_64_2, val_generator_64_2 = load_data(data_path, img_width=64, img_height=64, \n",
        "                                           batch_size=128, augmentation=aug, seed=None)\n",
        "new_model2, history2 = training(new_model2, 'new_model2', train_generator_64_2, val_generator_64_2, \n",
        "                           clr, checkpoint_filepath, epochs=25)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin loading...\n",
            "Found 80000 images belonging to 200 classes.\n",
            "Found 20000 images belonging to 200 classes.\n",
            "Training data shape: (80000, 64, 64, 3)\n",
            "Validation data shape: (20000, 64, 64, 3)\n",
            "End loading!\n",
            "Epoch 1/25\n",
            "200/200 [==============================] - 427s 2s/step - loss: 4.8323 - accuracy: 0.1148 - val_loss: 4.8791 - val_accuracy: 0.1096\n",
            "Epoch 2/25\n",
            "200/200 [==============================] - 410s 2s/step - loss: 4.7780 - accuracy: 0.1199 - val_loss: 4.8131 - val_accuracy: 0.1173\n",
            "Epoch 3/25\n",
            "200/200 [==============================] - 408s 2s/step - loss: 4.7319 - accuracy: 0.1229 - val_loss: 4.8201 - val_accuracy: 0.1113\n",
            "Epoch 4/25\n",
            "200/200 [==============================] - 404s 2s/step - loss: 4.6740 - accuracy: 0.1259 - val_loss: 4.8851 - val_accuracy: 0.1101\n",
            "Epoch 5/25\n",
            "200/200 [==============================] - 400s 2s/step - loss: 4.6501 - accuracy: 0.1300 - val_loss: 4.7994 - val_accuracy: 0.1186\n",
            "Epoch 6/25\n",
            "200/200 [==============================] - 402s 2s/step - loss: 4.6055 - accuracy: 0.1364 - val_loss: 4.6996 - val_accuracy: 0.1291\n",
            "Epoch 7/25\n",
            "200/200 [==============================] - 403s 2s/step - loss: 4.5433 - accuracy: 0.1399 - val_loss: 4.7458 - val_accuracy: 0.1217\n",
            "Epoch 8/25\n",
            "200/200 [==============================] - 403s 2s/step - loss: 4.5059 - accuracy: 0.1447 - val_loss: 4.8926 - val_accuracy: 0.1041\n",
            "Epoch 9/25\n",
            "200/200 [==============================] - 400s 2s/step - loss: 4.4624 - accuracy: 0.1488 - val_loss: 4.9486 - val_accuracy: 0.1032\n",
            "Epoch 10/25\n",
            "200/200 [==============================] - 395s 2s/step - loss: 4.4253 - accuracy: 0.1521 - val_loss: 4.6411 - val_accuracy: 0.1282\n",
            "Epoch 11/25\n",
            "200/200 [==============================] - 391s 2s/step - loss: 4.3899 - accuracy: 0.1579 - val_loss: 4.5945 - val_accuracy: 0.1325\n",
            "Epoch 12/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.3703 - accuracy: 0.1572 - val_loss: 4.7640 - val_accuracy: 0.1204\n",
            "Epoch 13/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.3160 - accuracy: 0.1676 - val_loss: 4.7243 - val_accuracy: 0.1275\n",
            "Epoch 14/25\n",
            "200/200 [==============================] - 391s 2s/step - loss: 4.3146 - accuracy: 0.1670 - val_loss: 4.6461 - val_accuracy: 0.1320\n",
            "Epoch 15/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.2776 - accuracy: 0.1723 - val_loss: 4.8226 - val_accuracy: 0.1286\n",
            "Epoch 16/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.2611 - accuracy: 0.1737 - val_loss: 4.6265 - val_accuracy: 0.1318\n",
            "Epoch 17/25\n",
            "200/200 [==============================] - 392s 2s/step - loss: 4.2422 - accuracy: 0.1762 - val_loss: 4.6220 - val_accuracy: 0.1324\n",
            "Epoch 18/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.2301 - accuracy: 0.1798 - val_loss: 4.7404 - val_accuracy: 0.1245\n",
            "Epoch 19/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.1833 - accuracy: 0.1840 - val_loss: 4.8432 - val_accuracy: 0.1177\n",
            "Epoch 20/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.1818 - accuracy: 0.1896 - val_loss: 4.7117 - val_accuracy: 0.1364\n",
            "Epoch 21/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 4.1632 - accuracy: 0.1912 - val_loss: 4.5259 - val_accuracy: 0.1532\n",
            "Epoch 22/25\n",
            "200/200 [==============================] - 391s 2s/step - loss: 4.1463 - accuracy: 0.1992 - val_loss: 4.8411 - val_accuracy: 0.1162\n",
            "Epoch 23/25\n",
            "200/200 [==============================] - 391s 2s/step - loss: 4.1406 - accuracy: 0.1993 - val_loss: 4.4016 - val_accuracy: 0.1667\n",
            "Epoch 24/25\n",
            "200/200 [==============================] - 394s 2s/step - loss: 4.1344 - accuracy: 0.2043 - val_loss: 4.4847 - val_accuracy: 0.1629\n",
            "Epoch 25/25\n",
            "200/200 [==============================] - 398s 2s/step - loss: 4.0949 - accuracy: 0.2044 - val_loss: 4.5743 - val_accuracy: 0.1473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ1mbEXmOAaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77948d12-a91b-400d-8bdb-b649543c167f"
      },
      "source": [
        "save_model(new_model2, 'new_model2', model_path+'/models')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new_model2_12-20_02-05.h5 saved at /content/drive/MyDrive/Colab Notebooks/4040/savedmodel/models!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3DSH9CH6S5p",
        "outputId": "80af63fd-c2c9-41d5-be97-e8822ae3a3ae"
      },
      "source": [
        "model2550, history3 = training(new_model2, 'model2550', train_generator_64_2, val_generator_64_2, \r\n",
        "                           clr, checkpoint_filepath, epochs=25)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "200/200 [==============================] - 408s 2s/step - loss: 4.0386 - accuracy: 0.2176 - val_loss: 4.4027 - val_accuracy: 0.1669\n",
            "Epoch 2/25\n",
            "200/200 [==============================] - 392s 2s/step - loss: 4.0262 - accuracy: 0.2191 - val_loss: 4.3011 - val_accuracy: 0.1777\n",
            "Epoch 3/25\n",
            "200/200 [==============================] - 393s 2s/step - loss: 3.9722 - accuracy: 0.2270 - val_loss: 4.3521 - val_accuracy: 0.1773\n",
            "Epoch 4/25\n",
            "200/200 [==============================] - 388s 2s/step - loss: 3.9237 - accuracy: 0.2329 - val_loss: 4.2757 - val_accuracy: 0.1857\n",
            "Epoch 5/25\n",
            "200/200 [==============================] - 389s 2s/step - loss: 3.8752 - accuracy: 0.2446 - val_loss: 4.1495 - val_accuracy: 0.2008\n",
            "Epoch 6/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 3.8420 - accuracy: 0.2497 - val_loss: 4.1867 - val_accuracy: 0.2024\n",
            "Epoch 7/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 3.8034 - accuracy: 0.2548 - val_loss: 4.3079 - val_accuracy: 0.1894\n",
            "Epoch 8/25\n",
            "200/200 [==============================] - 387s 2s/step - loss: 3.7399 - accuracy: 0.2619 - val_loss: 4.1192 - val_accuracy: 0.2128\n",
            "Epoch 9/25\n",
            "200/200 [==============================] - 394s 2s/step - loss: 3.6871 - accuracy: 0.2736 - val_loss: 3.9997 - val_accuracy: 0.2268\n",
            "Epoch 10/25\n",
            "200/200 [==============================] - 420s 2s/step - loss: 3.6617 - accuracy: 0.2785 - val_loss: 4.1095 - val_accuracy: 0.2091\n",
            "Epoch 11/25\n",
            "200/200 [==============================] - 403s 2s/step - loss: 3.6205 - accuracy: 0.2871 - val_loss: 3.9830 - val_accuracy: 0.2289\n",
            "Epoch 12/25\n",
            "200/200 [==============================] - 396s 2s/step - loss: 3.5888 - accuracy: 0.2904 - val_loss: 3.9379 - val_accuracy: 0.2326\n",
            "Epoch 13/25\n",
            "200/200 [==============================] - 391s 2s/step - loss: 3.5366 - accuracy: 0.2966 - val_loss: 3.9215 - val_accuracy: 0.2373\n",
            "Epoch 14/25\n",
            "200/200 [==============================] - 390s 2s/step - loss: 3.4840 - accuracy: 0.3082 - val_loss: 3.7688 - val_accuracy: 0.2589\n",
            "Epoch 15/25\n",
            "200/200 [==============================] - 389s 2s/step - loss: 3.4564 - accuracy: 0.3115 - val_loss: 3.9910 - val_accuracy: 0.2310\n",
            "Epoch 16/25\n",
            "200/200 [==============================] - 397s 2s/step - loss: 3.4008 - accuracy: 0.3190 - val_loss: 3.6747 - val_accuracy: 0.2762\n",
            "Epoch 17/25\n",
            "200/200 [==============================] - 391s 2s/step - loss: 3.3579 - accuracy: 0.3296 - val_loss: 3.7613 - val_accuracy: 0.2590\n",
            "Epoch 18/25\n",
            "200/200 [==============================] - 392s 2s/step - loss: 3.3187 - accuracy: 0.3313 - val_loss: 3.6041 - val_accuracy: 0.2841\n",
            "Epoch 19/25\n",
            "200/200 [==============================] - 396s 2s/step - loss: 3.2688 - accuracy: 0.3428 - val_loss: 3.5558 - val_accuracy: 0.2940\n",
            "Epoch 20/25\n",
            "200/200 [==============================] - 407s 2s/step - loss: 3.2312 - accuracy: 0.3489 - val_loss: 3.5059 - val_accuracy: 0.3006\n",
            "Epoch 21/25\n",
            "200/200 [==============================] - 408s 2s/step - loss: 3.1771 - accuracy: 0.3592 - val_loss: 3.3942 - val_accuracy: 0.3185\n",
            "Epoch 22/25\n",
            "200/200 [==============================] - 403s 2s/step - loss: 3.1277 - accuracy: 0.3664 - val_loss: 3.4603 - val_accuracy: 0.3056\n",
            "Epoch 23/25\n",
            "200/200 [==============================] - 396s 2s/step - loss: 3.0997 - accuracy: 0.3735 - val_loss: 3.3338 - val_accuracy: 0.3298\n",
            "Epoch 24/25\n",
            "200/200 [==============================] - 398s 2s/step - loss: 3.0858 - accuracy: 0.3746 - val_loss: 3.3715 - val_accuracy: 0.3221\n",
            "Epoch 25/25\n",
            "200/200 [==============================] - 392s 2s/step - loss: 3.0997 - accuracy: 0.3704 - val_loss: 3.3428 - val_accuracy: 0.3305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeCNICDInxJ-",
        "outputId": "b45eea34-6636-440c-de6c-09c89a854539"
      },
      "source": [
        "save_model(model2550, 'model2550', model_path+'/models')\r\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model2550_12-20_05-29.h5 saved at /content/drive/MyDrive/Colab Notebooks/4040/savedmodel/models!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4oeC2WHohfp",
        "outputId": "ee296c1c-5dab-4f3e-8c89-24cde1e1ec18"
      },
      "source": [
        "model50100, history4 = training(model2550, 'model50100', train_generator_64_2, val_generator_64_2, \r\n",
        "                           clr, checkpoint_filepath, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - 408s 2s/step - loss: 3.1033 - accuracy: 0.3681 - val_loss: 3.4591 - val_accuracy: 0.3070\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 402s 2s/step - loss: 3.1107 - accuracy: 0.3659 - val_loss: 3.3411 - val_accuracy: 0.3257\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 398s 2s/step - loss: 3.1141 - accuracy: 0.3623 - val_loss: 3.4054 - val_accuracy: 0.3126\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 395s 2s/step - loss: 3.1153 - accuracy: 0.3665 - val_loss: 3.4959 - val_accuracy: 0.3022\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 397s 2s/step - loss: 3.1256 - accuracy: 0.3602 - val_loss: 3.4910 - val_accuracy: 0.3054\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 396s 2s/step - loss: 3.1183 - accuracy: 0.3650 - val_loss: 3.5017 - val_accuracy: 0.3033\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 396s 2s/step - loss: 3.1170 - accuracy: 0.3636 - val_loss: 3.4973 - val_accuracy: 0.3009\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 395s 2s/step - loss: 3.1331 - accuracy: 0.3628 - val_loss: 3.5534 - val_accuracy: 0.2876\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 393s 2s/step - loss: 3.1382 - accuracy: 0.3659 - val_loss: 3.6165 - val_accuracy: 0.2837\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 392s 2s/step - loss: 3.1585 - accuracy: 0.3584 - val_loss: 3.5464 - val_accuracy: 0.2987\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 394s 2s/step - loss: 3.1580 - accuracy: 0.3609 - val_loss: 3.6737 - val_accuracy: 0.2768\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 392s 2s/step - loss: 3.1602 - accuracy: 0.3625 - val_loss: 3.6432 - val_accuracy: 0.2767\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 394s 2s/step - loss: 3.1641 - accuracy: 0.3554 - val_loss: 3.5949 - val_accuracy: 0.2893\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 392s 2s/step - loss: 3.1758 - accuracy: 0.3614 - val_loss: 3.7903 - val_accuracy: 0.2676\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 393s 2s/step - loss: 3.1922 - accuracy: 0.3525 - val_loss: 3.7092 - val_accuracy: 0.2725\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 395s 2s/step - loss: 3.2091 - accuracy: 0.3517 - val_loss: 3.7149 - val_accuracy: 0.2725\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 393s 2s/step - loss: 3.2151 - accuracy: 0.3534 - val_loss: 3.7694 - val_accuracy: 0.2623\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 394s 2s/step - loss: 3.2211 - accuracy: 0.3546 - val_loss: 3.7910 - val_accuracy: 0.2636\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 395s 2s/step - loss: 3.2293 - accuracy: 0.3504 - val_loss: 3.8124 - val_accuracy: 0.2607\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 397s 2s/step - loss: 3.2335 - accuracy: 0.3586 - val_loss: 3.8330 - val_accuracy: 0.2616\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 396s 2s/step - loss: 3.2405 - accuracy: 0.3562 - val_loss: 3.7777 - val_accuracy: 0.2664\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 397s 2s/step - loss: 3.1928 - accuracy: 0.3644 - val_loss: 3.7622 - val_accuracy: 0.2726\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 394s 2s/step - loss: 3.2053 - accuracy: 0.3640 - val_loss: 3.6674 - val_accuracy: 0.2862\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 394s 2s/step - loss: 3.1921 - accuracy: 0.3669 - val_loss: 3.6478 - val_accuracy: 0.2928\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 391s 2s/step - loss: 3.1818 - accuracy: 0.3662 - val_loss: 3.7499 - val_accuracy: 0.2833\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 397s 2s/step - loss: 3.1423 - accuracy: 0.3732 - val_loss: 3.6017 - val_accuracy: 0.3002\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 399s 2s/step - loss: 3.1341 - accuracy: 0.3793 - val_loss: 3.6203 - val_accuracy: 0.2959\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 394s 2s/step - loss: 3.1041 - accuracy: 0.3847 - val_loss: 3.5845 - val_accuracy: 0.3009\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 391s 2s/step - loss: 3.0836 - accuracy: 0.3843 - val_loss: 3.5800 - val_accuracy: 0.3128\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 392s 2s/step - loss: 3.0638 - accuracy: 0.3902 - val_loss: 3.4971 - val_accuracy: 0.3131\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 391s 2s/step - loss: 3.0242 - accuracy: 0.3984 - val_loss: 3.5149 - val_accuracy: 0.3101\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 391s 2s/step - loss: 3.0023 - accuracy: 0.3987 - val_loss: 3.4580 - val_accuracy: 0.3295\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 391s 2s/step - loss: 2.9928 - accuracy: 0.4072 - val_loss: 3.4111 - val_accuracy: 0.3338\n",
            "Epoch 34/50\n",
            " 34/200 [====>.........................] - ETA: 3:17 - loss: 2.9712 - accuracy: 0.4007"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXyiWSDodxkS"
      },
      "source": [
        "# After disconnecting and saving the model, run the new model from here after skipping the above part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg0-B4Vr-90B"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "model5083 = load_model(\"/content/drive/MyDrive/Colab Notebooks/4040/checkpoints/model50100_12-20_05-33.33.h5\")\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZB5I6YD_3Nn",
        "outputId": "7e9a1abc-e550-4ef9-83cb-3614a7db1979"
      },
      "source": [
        "\r\n",
        "\r\n",
        "aug = data_augmentation(complicated=True, **data_aug_args)\r\n",
        "clr = CyclicLR(base_lr=0.0001, max_lr=0.0006, step_size=4686., mode='triangular2')\r\n",
        "train_generator_64_2, val_generator_64_2 = load_data(data_path, img_width=64, img_height=64, \r\n",
        "                                           batch_size=128, augmentation=aug, seed=None)\r\n",
        "num_train=80000\r\n",
        "batch_size=256\r\n",
        "model83103, history5 = training(model5083, \r\n",
        "                                'model83103', \r\n",
        "                                train_generator_64_2, \r\n",
        "                                val_generator_64_2, \r\n",
        "                                clr, \r\n",
        "                                checkpoint_filepath, \r\n",
        "                                epochs=20, \r\n",
        "                                steps_per_epoch=num_train // batch_size)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin loading...\n",
            "Found 80000 images belonging to 200 classes.\n",
            "Found 20000 images belonging to 200 classes.\n",
            "Training data shape: (80000, 64, 64, 3)\n",
            "Validation data shape: (20000, 64, 64, 3)\n",
            "End loading!\n",
            "Epoch 1/20\n",
            "312/312 [==============================] - 520s 2s/step - loss: 2.8787 - accuracy: 0.4221 - val_loss: 3.2146 - val_accuracy: 0.3648\n",
            "Epoch 2/20\n",
            "312/312 [==============================] - 521s 2s/step - loss: 2.8075 - accuracy: 0.4403 - val_loss: 3.2242 - val_accuracy: 0.3632\n",
            "Epoch 3/20\n",
            "312/312 [==============================] - 520s 2s/step - loss: 2.8165 - accuracy: 0.4336 - val_loss: 3.3352 - val_accuracy: 0.3480\n",
            "Epoch 4/20\n",
            "312/312 [==============================] - 519s 2s/step - loss: 2.8569 - accuracy: 0.4265 - val_loss: 3.6036 - val_accuracy: 0.3007\n",
            "Epoch 5/20\n",
            "312/312 [==============================] - 515s 2s/step - loss: 2.9444 - accuracy: 0.4066 - val_loss: 3.4252 - val_accuracy: 0.3257\n",
            "Epoch 6/20\n",
            "312/312 [==============================] - 529s 2s/step - loss: 2.9588 - accuracy: 0.4112 - val_loss: 3.5656 - val_accuracy: 0.3090\n",
            "Epoch 7/20\n",
            "312/312 [==============================] - 544s 2s/step - loss: 3.0078 - accuracy: 0.4036 - val_loss: 4.1479 - val_accuracy: 0.2400\n",
            "Epoch 8/20\n",
            "312/312 [==============================] - 549s 2s/step - loss: 3.0667 - accuracy: 0.3925 - val_loss: 3.8872 - val_accuracy: 0.2691\n",
            "Epoch 9/20\n",
            "312/312 [==============================] - 550s 2s/step - loss: 3.0946 - accuracy: 0.3873 - val_loss: 3.9116 - val_accuracy: 0.2692\n",
            "Epoch 10/20\n",
            "312/312 [==============================] - 544s 2s/step - loss: 3.1332 - accuracy: 0.3819 - val_loss: 3.8818 - val_accuracy: 0.2707\n",
            "Epoch 11/20\n",
            "312/312 [==============================] - 549s 2s/step - loss: 3.2036 - accuracy: 0.3729 - val_loss: 3.8260 - val_accuracy: 0.2751\n",
            "Epoch 12/20\n",
            "312/312 [==============================] - 551s 2s/step - loss: 3.2436 - accuracy: 0.3680 - val_loss: 3.8251 - val_accuracy: 0.2797\n",
            "Epoch 13/20\n",
            "312/312 [==============================] - 551s 2s/step - loss: 3.2442 - accuracy: 0.3728 - val_loss: 4.0960 - val_accuracy: 0.2437\n",
            "Epoch 14/20\n",
            "312/312 [==============================] - 554s 2s/step - loss: 3.3237 - accuracy: 0.3613 - val_loss: 3.9955 - val_accuracy: 0.2515\n",
            "Epoch 15/20\n",
            "312/312 [==============================] - 557s 2s/step - loss: 3.3377 - accuracy: 0.3588 - val_loss: 3.9612 - val_accuracy: 0.2563\n",
            "Epoch 16/20\n",
            "312/312 [==============================] - 560s 2s/step - loss: 3.3485 - accuracy: 0.3656 - val_loss: 4.0261 - val_accuracy: 0.2596\n",
            "Epoch 17/20\n",
            "312/312 [==============================] - 560s 2s/step - loss: 3.3386 - accuracy: 0.3637 - val_loss: 4.1520 - val_accuracy: 0.2398\n",
            "Epoch 18/20\n",
            "312/312 [==============================] - 558s 2s/step - loss: 3.3026 - accuracy: 0.3751 - val_loss: 4.0519 - val_accuracy: 0.2639\n",
            "Epoch 19/20\n",
            "312/312 [==============================] - 554s 2s/step - loss: 3.2767 - accuracy: 0.3771 - val_loss: 4.0190 - val_accuracy: 0.2630\n",
            "Epoch 20/20\n",
            "312/312 [==============================] - 554s 2s/step - loss: 3.2217 - accuracy: 0.3855 - val_loss: 3.9093 - val_accuracy: 0.2822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "xupspTy8FQU2",
        "outputId": "96ae4093-3821-4798-e6f7-bec349132e64"
      },
      "source": [
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.00006, step_size=4686., mode='triangular2')\r\n",
        "train_generator_64_2, val_generator_64_2 = load_data(data_path, img_width=64, img_height=64, \r\n",
        "                                           batch_size=128, augmentation=aug, seed=None)\r\n",
        "num_train=80000\r\n",
        "batch_size=128\r\n",
        "model103123, history6= training(model83103, \r\n",
        "                                'model103123', \r\n",
        "                                train_generator_64_2, \r\n",
        "                                val_generator_64_2, \r\n",
        "                                clr, \r\n",
        "                                checkpoint_filepath, \r\n",
        "                                epochs=20, \r\n",
        "                                steps_per_epoch=num_train // batch_size)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin loading...\n",
            "Found 80000 images belonging to 200 classes.\n",
            "Found 20000 images belonging to 200 classes.\n",
            "Training data shape: (80000, 64, 64, 3)\n",
            "Validation data shape: (20000, 64, 64, 3)\n",
            "End loading!\n",
            "Epoch 1/20\n",
            "625/625 [==============================] - 925s 1s/step - loss: 2.9957 - accuracy: 0.4379 - val_loss: 3.2187 - val_accuracy: 0.3982\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 938s 2s/step - loss: 2.8773 - accuracy: 0.4604 - val_loss: 3.1481 - val_accuracy: 0.4095\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 951s 2s/step - loss: 2.8131 - accuracy: 0.4729 - val_loss: 3.1080 - val_accuracy: 0.4173\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 941s 2s/step - loss: 2.7676 - accuracy: 0.4775 - val_loss: 3.0765 - val_accuracy: 0.4202\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 942s 2s/step - loss: 2.7244 - accuracy: 0.4833 - val_loss: 3.0576 - val_accuracy: 0.4195\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 943s 2s/step - loss: 2.6916 - accuracy: 0.4869 - val_loss: 3.0342 - val_accuracy: 0.4216\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 943s 2s/step - loss: 2.6619 - accuracy: 0.4906 - val_loss: 3.0182 - val_accuracy: 0.4225\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 936s 1s/step - loss: 2.6287 - accuracy: 0.4969 - val_loss: 2.9874 - val_accuracy: 0.4281\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 969s 2s/step - loss: 2.5974 - accuracy: 0.4999 - val_loss: 2.9822 - val_accuracy: 0.4288\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 948s 2s/step - loss: 2.5563 - accuracy: 0.5071 - val_loss: 2.9396 - val_accuracy: 0.4351\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 949s 2s/step - loss: 2.5211 - accuracy: 0.5140 - val_loss: 2.9227 - val_accuracy: 0.4374\n",
            "Epoch 12/20\n",
            " 88/625 [===>..........................] - ETA: 11:14 - loss: 2.4666 - accuracy: 0.5270"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-79ba9bb17c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 \u001b[0mcheckpoint_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                 steps_per_epoch=num_train // batch_size)\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/4040/models.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, model_name, train_generator, val_generator, callback, checkpoint_filepath, epochs, steps_per_epoch)\u001b[0m\n\u001b[1;32m    209\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                         callbacks=[callback, checkpoint])\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px8PROoj_VcH"
      },
      "source": [
        "# After disconnecting and saving the model, run the new model from here after skipping the above part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz0c2Y1z_Y-P"
      },
      "source": [
        "\r\n",
        "from keras.models import load_model\r\n",
        "model114 = load_model(\"/content/drive/MyDrive/Colab Notebooks/4040/checkpoints/model114_12-21_00-37.01.h5\")\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwhA_EgN_rtt"
      },
      "source": [
        "opt1=RMSprop(lr= 1e-4, epsilon=1e-08)\r\n",
        "opt2= Adam(lr= 1e-4, epsilon=1e-08)\r\n",
        "opt3= SGD(momentum=0.9)\r\n",
        "model114.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt2,\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rICwomnG_vJn",
        "outputId": "c6e0553a-83c9-46b3-e055-1a36899ca32c"
      },
      "source": [
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.00006, step_size=4686., mode='triangular2')\r\n",
        "train_generator_64_2, val_generator_64_2 = load_data(data_path, img_width=64, img_height=64, \r\n",
        "                                           batch_size=128, augmentation=aug, seed=None)\r\n",
        "num_train=80000\r\n",
        "batch_size=128\r\n",
        "model115, history7= training(model114, \r\n",
        "                                'model115', \r\n",
        "                                train_generator_64_2, \r\n",
        "                                val_generator_64_2, \r\n",
        "                                clr, \r\n",
        "                                checkpoint_filepath, \r\n",
        "                                epochs=12, \r\n",
        "                                steps_per_epoch=num_train // batch_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin loading...\n",
            "Found 80000 images belonging to 200 classes.\n",
            "Found 20000 images belonging to 200 classes.\n",
            "Training data shape: (80000, 64, 64, 3)\n",
            "Validation data shape: (20000, 64, 64, 3)\n",
            "End loading!\n",
            "Epoch 1/12\n",
            "  6/625 [..............................] - ETA: 7:29 - loss: 3.1353 - accuracy: 0.3932WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2616s vs `on_train_batch_end` time: 0.4615s). Check your callbacks.\n",
            "625/625 [==============================] - 542s 866ms/step - loss: 2.9124 - accuracy: 0.4384 - val_loss: 3.1704 - val_accuracy: 0.3922\n",
            "Epoch 2/12\n",
            "625/625 [==============================] - 540s 863ms/step - loss: 2.7345 - accuracy: 0.4707 - val_loss: 3.0967 - val_accuracy: 0.4050\n",
            "Epoch 3/12\n",
            "625/625 [==============================] - 540s 864ms/step - loss: 2.6657 - accuracy: 0.4850 - val_loss: 3.0414 - val_accuracy: 0.4132\n",
            "Epoch 4/12\n",
            "625/625 [==============================] - 540s 863ms/step - loss: 2.6114 - accuracy: 0.4955 - val_loss: 2.9901 - val_accuracy: 0.4249\n",
            "Epoch 5/12\n",
            "625/625 [==============================] - 539s 862ms/step - loss: 2.5641 - accuracy: 0.5032 - val_loss: 2.9989 - val_accuracy: 0.4180\n",
            "Epoch 6/12\n",
            "625/625 [==============================] - 540s 863ms/step - loss: 2.5275 - accuracy: 0.5117 - val_loss: 2.9786 - val_accuracy: 0.4230\n",
            "Epoch 7/12\n",
            "625/625 [==============================] - 540s 864ms/step - loss: 2.4830 - accuracy: 0.5187 - val_loss: 2.9781 - val_accuracy: 0.4234\n",
            "Epoch 8/12\n",
            "625/625 [==============================] - 539s 862ms/step - loss: 2.4436 - accuracy: 0.5248 - val_loss: 2.9297 - val_accuracy: 0.4268\n",
            "Epoch 9/12\n",
            "625/625 [==============================] - 540s 864ms/step - loss: 2.4006 - accuracy: 0.5352 - val_loss: 2.9405 - val_accuracy: 0.4266\n",
            "Epoch 10/12\n",
            "625/625 [==============================] - 541s 865ms/step - loss: 2.3444 - accuracy: 0.5458 - val_loss: 2.9013 - val_accuracy: 0.4360\n",
            "Epoch 11/12\n",
            "625/625 [==============================] - 540s 864ms/step - loss: 2.3073 - accuracy: 0.5565 - val_loss: 2.8667 - val_accuracy: 0.4394\n",
            "Epoch 12/12\n",
            "625/625 [==============================] - 540s 863ms/step - loss: 2.2667 - accuracy: 0.5638 - val_loss: 2.8463 - val_accuracy: 0.4475\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}